# create an plot matrix with ggpairs()
ggpairs(analysis_dataset, lower = list(combo = wrap("facethist", bins = 20)))
# create a regression model with multiple explanatory variables
my_model2 <- lm(points ~ attitude + stra + surf, data = analysis_dataset)
# print out a summary of the model
summary(my_model2)
my_model2 <- lm(points ~ attitude + stra + deep, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude + stra + gender, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude + deep + surf, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude + stra + surf, data = analysis_dataset)
summary(my_model2)
library(ggplot2)
qplot(attitude, points, data = analysis_dataset) + geom_smooth(method = "lm")
my_model <- lm(points ~ attitude, data = analysis_dataset)
summary(my_model)
my_model <- lm(points ~ attitude + strat, data = analysis_dataset)
my_model <- lm(points ~ attitude + stra, data = analysis_dataset)
summary(my_model)
qplot(attitude, points, data = analysis_dataset) + geom_smooth(method = "lm")
my_model <- lm(points ~ attitude + stra, data = analysis_dataset)
summary(my_model)
my_model <- lm(points ~ attitude + stra + surf, data = analysis_dataset)
summary(my_model)
qplot(stra, points, data = analysis_dataset) + geom_smooth(method = "lm")
qplot(surf, points, data = analysis_dataset) + geom_smooth(method = "lm")
qplot(deep, points, data = analysis_dataset) + geom_smooth(method = "lm")
my_model <- lm(points ~ attitude + stra + surf, data = analysis_dataset)
summary(my_model)
my_model <- lm(points ~ attitude + stra + deep, data = analysis_dataset)
summary(my_model)
my_model <- lm(points ~ attitude + stra + surf, data = analysis_dataset)
summary(my_model)
my_model2 <- lm(points ~ attitude + stra + surf, data = analysis_dataset)
summary(my_model2)
plot(my_model2)
chartr(my_model2)
print(my_model2)
summary(my_model2)
my_model2 <- lm(points ~ attitude + stra, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude + stra, data = analysis_dataset)
summary(my_model2)
options(scipen = 999)
my_model2 <- lm(points ~ attitude + stra, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude + stra + surf, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude + stra, data = analysis_dataset)
summary(my_model2)
my_model2 <- lm(points ~ attitude, data = analysis_dataset)
summary(my_model2)
library(ggplot2)
# initialize plot with data and aesthetic mapping
p1 <- ggplot(learning2014, aes(x = attitude, y = points, col = gender))
# define the visualization type (points)
p2 <- p1 + geom_point()
# draw the plot
p2
# add a regression line
p3 <- p2 + geom_smooth(method = "lm")
# add a main title and draw the plot
p4 <- p3 + ggtitle("Student's attitude versus exam points")
p4
library(ggplot2)
# initialize plot with data and aesthetic mapping
p1 <- ggplot(analysis_dataset, aes(x = attitude, y = points, col = gender))
# define the visualization type (points)
p2 <- p1 + geom_point()
# draw the plot
p2
# add a regression line
p3 <- p2 + geom_smooth(method = "lm")
# add a main title and draw the plot
p4 <- p3 + ggtitle("Student's attitude versus exam points")
p4
library(ggplot2)
# initialize plot with data and aesthetic mapping
p1 <- ggplot(analysis_dataset, aes(x = attitude, y = points, col = gender))
# define the visualization type (points)
p2 <- p1 + geom_point()
# draw the plot
p2
# add a regression line
p3 <- p2 + geom_smooth(method = "lm")
# add a main title and draw the plot
p4 <- p3 + ggtitle("Student's attitude versus exam points (r=0.437")
p4
library(ggplot2)
# initialize plot with data and aesthetic mapping
p1 <- ggplot(analysis_dataset, aes(x = attitude, y = points, col = gender))
# define the visualization type (points)
p2 <- p1 + geom_point()
# draw the plot
p2
# add a regression line
p3 <- p2 + geom_smooth(method = "lm")
# add a main title and draw the plot
p4 <- p3 + ggtitle("Student's attitude versus exam points (r=0.437)")
p4
my_model2 <- lm(points ~ attitude + stra, data = learning2014)
my_model2 <- lm(points ~ attitude + stra, data = analysis_dataset)
par(mfrow = c(2,2))
plot(my_model2, which = c(1:2, 5))
library(ggplot2)
# create a regression model with multiple explanatory variables
my_model2 <- lm(attitude ~ surf, data = a)
# draw diagnostic plots using the plot() function. Choose the plots 1, 2 and 5
par(mfrow = c(2,2))
plot(my_model2, which = c(1:2, 5))
library(ggplot2)
# create a regression model with multiple explanatory variables
my_model2 <- lm(attitude ~ surf, data = analysis_dataset)
# draw diagnostic plots using the plot() function. Choose the plots 1, 2 and 5
par(mfrow = c(2,2))
plot(my_model2, which = c(1:2, 5))
# a scatter plot of points versus attitude
library(ggplot2)
qplot(attitude, points, data = analysis_dataset) + geom_smooth(method = "lm")
# fit a linear model
my_model <- lm(points ~ attitude, data = analysis_dataset)
# print out a summary of the model
summary(my_model)
# a scatter plot of points versus attitude
library(ggplot2)
qplot(attitude, surf, data = analysis_dataset) + geom_smooth(method = "lm")
# fit a linear model
my_model <- lm(surf ~ attitude, data = analysis_dataset)
# print out a summary of the model
summary(my_model)
# a scatter plot of points versus attitude
library(ggplot2)
qplot(attitude, deep, data = analysis_dataset) + geom_smooth(method = "lm")
# fit a linear model
my_model <- lm(deep ~ attitude, data = analysis_dataset)
# print out a summary of the model
summary(my_model)
# a scatter plot of points versus attitude
library(ggplot2)
qplot(attitude, surf, data = analysis_dataset) + geom_smooth(method = "lm")
# fit a linear model
my_model <- lm(surf ~ attitude, data = analysis_dataset)
# print out a summary of the model
summary(my_model)
# Sampsa Huttunen, 26.1.2017, Wrangling Data from 'JYTOPKYS3_data' to 'analysis_dataset'
# Access the dplyr library
library(dplyr)
# reading data from a file
JYTOPKYS3_data <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep = "\t", header = TRUE)
# viewing JYTOPKYS3_data: a dataset containing information of 183 individuals
View(JYTOPKYS3_data)
# inspecting JYTOPKYS3_data
dim(JYTOPKYS3_data)
# inspecting JYTOPKYS3_data
str(JYTOPKYS3_data)
# inspecting JYTOPKYS3_data
summary(JYTOPKYS3_data)
# Changing name of Age to age
colnames(JYTOPKYS3_data)[57] <- "age"
# Changing name of Attitude to attitude
colnames(JYTOPKYS3_data)[58] <- "attitude"
# Changing name of Points to points
colnames(JYTOPKYS3_data)[59] <- "points"
# print out the column names in data
colnames(JYTOPKYS3_data)
# choosing questions related to deep and surface learning, and learning strategies
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30", "D06", "D15", "D23", "D31")
surface_questions <- c("SU02", "SU10", "SU18", "SU26", "SU05", "SU13", "SU21", "SU29", "SU08", "SU16", "SU24", "SU32")
strategic_questions <- c("ST01", "ST09", "ST17", "ST25", "ST04", "ST12", "ST20", "ST28")
# changing 'attitude' back to likert-scale (1-5)
JYTOPKYS3_data$attitude <- JYTOPKYS3_data$attitude/10
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(JYTOPKYS3_data, one_of(deep_questions))
JYTOPKYS3_data$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(JYTOPKYS3_data, one_of(surface_questions))
JYTOPKYS3_data$surf <- rowMeans(surface_columns)
# select the columns related to learning strategies and create column 'stra' by averaging
strategic_columns <- select(JYTOPKYS3_data, one_of(strategic_questions))
JYTOPKYS3_data$stra <- rowMeans(strategic_columns)
# creating a set of desired columns
keep_columns <- c("gender", "age", "attitude", "deep", "stra", "surf", "points")
# creating a new dataset by choosing 'keep_columns' from the original dataset
# Tha data now has 166 individuals and 7 variables
analysis_dataset <- select(JYTOPKYS3_data, one_of(keep_columns))
colnames(analysis_dataset)
analysis_dataset <- filter(analysis_dataset, points != 0)
dim(analysis_dataset)
dim(JYTOPKYS3_data)
dim(JYTOPKYS3_data)
str(JYTOPKYS3_data)
summary(JYTOPKYS3_data)
dim(analysis_dataset)
str(analysis_dataset)
head(analysis_dataset)
View(analysis_dataset)
dim(analysis_dataset)
# Sampsa Huttunen, 26.1.2017, Wrangling Data from 'JYTOPKYS3_data' to 'analysis_dataset'
# Access the dplyr library
library(dplyr)
# reading data from a file
JYTOPKYS3_data <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep = "\t", header = TRUE)
# viewing JYTOPKYS3_data: a dataset containing information of 183 observations and 63 variables
View(JYTOPKYS3_data)
# inspecting JYTOPKYS3_data
dim(JYTOPKYS3_data)
# inspecting JYTOPKYS3_data
str(JYTOPKYS3_data)
# inspecting JYTOPKYS3_data
summary(JYTOPKYS3_data)
# Changing name of Age to age
colnames(JYTOPKYS3_data)[57] <- "age"
# Changing name of Attitude to attitude
colnames(JYTOPKYS3_data)[58] <- "attitude"
# Changing name of Points to points
colnames(JYTOPKYS3_data)[59] <- "points"
# print out the column names in data
colnames(JYTOPKYS3_data)
# choosing questions related to deep and surface learning, and learning strategies
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30", "D06", "D15", "D23", "D31")
surface_questions <- c("SU02", "SU10", "SU18", "SU26", "SU05", "SU13", "SU21", "SU29", "SU08", "SU16", "SU24", "SU32")
strategic_questions <- c("ST01", "ST09", "ST17", "ST25", "ST04", "ST12", "ST20", "ST28")
# changing 'attitude' back to likert-scale (1-5)
JYTOPKYS3_data$attitude <- JYTOPKYS3_data$attitude/10
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(JYTOPKYS3_data, one_of(deep_questions))
JYTOPKYS3_data$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(JYTOPKYS3_data, one_of(surface_questions))
JYTOPKYS3_data$surf <- rowMeans(surface_columns)
# select the columns related to learning strategies and create column 'stra' by averaging
strategic_columns <- select(JYTOPKYS3_data, one_of(strategic_questions))
JYTOPKYS3_data$stra <- rowMeans(strategic_columns)
# creating a set of desired columns
keep_columns <- c("gender", "age", "attitude", "deep", "stra", "surf", "points")
# creating a new dataset by choosing 'keep_columns' from the original dataset
analysis_dataset <- select(JYTOPKYS3_data, one_of(keep_columns))
# print out the column names in the new dataset ("gender", "age", "attitude", "deep", "stra", "surf", "points")
colnames(analysis_dataset)
# exclude observations where 'points' = 0
analysis_dataset <- filter(analysis_dataset, points != 0)
# checking the number of observations and variables in the new dataset
# Tha data now has 166 observations and 7 variables
dim(analysis_dataset)
# write the new dataset to a .csv file
write.csv(analysis_dataset, file = "data/analysis_dataset.csv")
# read the dataset back from the .csv file to 'analysis_dataset' (for practice)
analysis_dataset <- read.csv("data/analysis_dataset.csv")
# checking structure of the new dataset
str(analysis_dataset)
head(analysis_dataset)
# viewing the new dataset
View(analysis_dataset)
my_model <- lm(points ~ age + attitude + stra, data= learning2014)
my_model <- lm(points ~ age + attitude + stra, data= analysis_dataset)
summary(my_model)
my_model <- lm(points ~ attitude + stra, data= analysis_dataset)
summary(my_model)
my_model <- lm(points ~ age + attitude, data= analysis_dataset)
summary(my_model)
loss_func(class = alc$high_use, prob = 0)
# Logistic Regression
### Data Wrangling
##### I have created a new dataset 'alcohol-joined' from two datasets of alcohol use habits and background info of Math and Portugese language course students, n=382 (198 females and 184 males, mean age of 16.6 years).
##### Data Files:
* The original datasets are [student-mat.csv](https://github.com/huttusam/IODS-project/blob/master/data/student-mat.csv) and [student-por.csv](https://github.com/huttusam/IODS-project/blob/master/data/student-por.csv)
* The new dataset is [alcohol-joined.csv](https://github.com/huttusam/IODS-project/blob/master/data/alcohol-joined.csv)
##### Script:
* The R script used to create the new dataset (*with comments explaining the process*) is [create_alc.R](https://github.com/huttusam/IODS-project/blob/master/data/create_alc.R)
### Analysis
The new dataset 'alc' has 382 observations and 35 variables. The variables are:
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
alc = read.table("data/alcohol-joined.csv", sep = ";", header = TRUE)
colnames(alc)
```
####The meaning of each variable is as follows:
* 1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)
* 2 sex - student's sex (binary: 'F' - female or 'M' - male)
* 3 age - student's age (numeric: from 15 to 22)
* 4 address - student's home address type (binary: 'U' - urban or 'R' - rural)
* 5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)
* 6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)
* 7 Medu - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 -  5th to 9th grade, 3 -  secondary education or 4 -  higher education)
* 8 Fedu - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 -  5th to 9th grade, 3 -  secondary education or 4 -  higher education)
* 9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')
* 10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')
* 11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')
* 12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')
* 13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)
* 14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)
* 15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)
* 16 schoolsup - extra educational support (binary: yes or no)
* 17 famsup - family educational support (binary: yes or no)
* 18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
* 19 activities - extra-curricular activities (binary: yes or no)
* 20 nursery - attended nursery school (binary: yes or no)
* 21 higher - wants to take higher education (binary: yes or no)
* 22 internet - Internet access at home (binary: yes or no)
* 23 romantic - with a romantic relationship (binary: yes or no)
* 24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
* 25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)
* 26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)
* 27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
* 28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
* 29 health - current health status (numeric: from 1 - very bad to 5 - very good)
* 30 absences - number of school absences (numeric: from 0 to 93)
...and then there are the student's grades that are averages of her Mathematics and Portugese language grades:
* 31 G1 - first period grade (numeric: from 0 to 20)
* 32 G2 - second period grade (numeric: from 0 to 20)
* 33 G3 - final grade (numeric: from 0 to 20, output target)
...the new variables, I have created in the data wrangling are:
* 34 alc_use - the average of workday and weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
* 35 high_use - if alc_use is more than 2, then TRUE else FALSE (binary: TRUE or FALSE)
####Relationship of alcohol consumption to other variables
Let's look at a graphical summarization of the data:
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# access the tidyverse libraries tidyr, dplyr, ggplot2
library(tidyverse);
# draw a bar plot of each variable
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
```
Interegsting variables to look at, considering their relation to alcohol consumption, would be, for example, sex, health, absences from classes and final grades. My hypothesis would be that men use more alcohol than women and that high alcohol consumption correlates with lower grades, more abscence and lower health status.
OK, let's see how the aformentioned four variables correlate with alcohol consumption by cross tabulating them and drawing some plots to illustrate these correlations:
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# produce summary statistics by sex and mean alcohol use
alc %>% group_by(sex) %>% summarise(count = n(), mean_alcuse = mean(alc_use))
# initialise a plot of sex and alc_use
g1 <- ggplot(alc, aes(x = sex, y = alc_use))
# define the plot as a boxplot and draw it
g1 + geom_boxplot() + ylab("Alcohol Use") + ggtitle("Student alcohol consumption by sex")
# produce summary statistics by high_use and mean final grade
alc %>% group_by(high_use) %>% summarise(mean_grade = mean(G3))
# initialize a plot of high_use and G3
g2 <- ggplot(alc, aes(x = high_use, y = G3))
# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ylab("grade") + ggtitle("Student final grades by alcohol consumption")
# produce summary statistics by high_use and mean absences
alc %>% group_by(high_use) %>% summarise(mean_abs = mean(absences))
# initialise a plot of high_use and absences
g3 <- ggplot(alc, aes(x = high_use, y = absences))
# define the plot as a boxplot and draw it
g3 + geom_boxplot() + ylab("Absences") + ggtitle("Student absences by alcohol consumption")
# produce summary statistics by high_use and health
alc %>% group_by(high_use) %>% summarise(mean_health = mean(health))
# initialise a plot of high_use and health
g4 <- ggplot(alc, aes(x = high_use, y = health))
# define the plot as a boxplot and draw it
g4 + geom_boxplot() + ylab("Health") + ggtitle("Student health by alcohol consumption")
```
By looking at the cross-tabulaions and graphical presentations above, we can see that male students report bigger alcohol consumption than their female peers. High alcohol use also seems to correlate slightly with lower final grades and more absences from classes. On the other hand, alcohol use does not seem to correlate with health, but we have to keep in mind that the participants of this study are very young (15-22 year olds, mean age 16.6 years) and health problems created by alcohol mostly accumulate over time.
###Logistical regression analysis
Next we fit a logistic regression model to explain high consumption of alcohol.
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# find the model with glm()
m <- glm(high_use ~ G3 + absences + health + sex, data = alc, family = "binomial")
```
The summary of our fitted model is
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# print out a summary of the model
summary(m)
```
... and the coefficients of the model as odds ratios with confidence intervals is
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# compute odds ratios (OR)
OR <- coef(m) %>% exp
# compute confidence intervals (CI)
CI = exp(confint(m))
# print out the odds ratios with their confidence intervals
cbind(OR, CI)
```
When we look at the above printout, we can see that final grades, amount of absences and gender can be used to predict the likelihood of high alcohol consumption reasonably well: lower grades, more absences, and being male increase the possibility of high alcohol use. On the other hand, health status doesn't seem to correlate with high alcohol use, which might be due to young age of participants.
###Predictive Power of the Model
Using the variables which, according to our logistic regression model, have a statistical relationship with alcohol consumption, let's perform a 2x2 cross tabulation of predictions versus the actual values and visualize both the actual values and predictions graphically.
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# find the model
m <- glm(high_use ~ G3 + absences + health + sex, data = alc, family = "binomial")
# predict the probability of high alcohol use
probabilities <- predict(m, type = "response")
# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)
# use probabilities to predict high alcohol use
alc <- mutate(alc, prediction = probability > 0.5)
# tabulate target variable vs predictions
table(high_use = alc$high_use, prediction = alc$prediction)
# initialize a plot of high_use vs. probability
g <- ggplot(alc, aes(x = probability, y = high_use, col=prediction))
# define the geom as points and draw the plot
g + geom_point()
```
And let's compute the total proportion of inaccurately classified observations (i.e. incorrect predicitions, training error):
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
n_wrong <- abs(class - prob) > 0.5
mean(n_wrong)
}
# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = 0)
```
... and, as a BONUS, do a 10-fold cross-validation:
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)
# average number of wrong predictions in the cross validation
cv$delta[1]
```
Our model estimates that 87 participants would not be and 12 would be high users when actually the opposite was true. The model accurately identified 27 participants as high users and 256 as not. Our graph tries to visualize the same, although the amount of accurately predicted non-high users (n=256) and inaccurately predicted high users (n=87) look quite similar (see red/left side of graph).
The training error of our model (0.26) is lower than way lower than if we were just to guess weather an individual has high or lowalcohol consumption a bit lower than our validation error (0.27) which means that our model has a good fit. about the same as in the model introduced in DataCamp (high_use ~ failures + absences + sex), which suggests that our model seems to work as well as the DataCamp model. better than the baseline model of including failures, absence and sex as explanatory variables. This is also the training error.
# find the model with glm()
m2 <- glm(high_use ~ freetime + absences + sex, data = alc, family = "binomial")
?cv
help(cv)
# Access GGally
library(GGally)
# visualize the 'human' variables
ggpairs(human)
summary(human)
# Dimensionality reduction techniques
##### This exercise analyses data from the wrangled *Human* dataset with 155 observations in 8 variables.
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# load the wrangled Human data
human = read.table("data/human.csv", sep = ";", header = TRUE)
# Dimensions of the data
dim(human)
```
##### Human is a subset of a dataset at http://hdr.undp.org/en/content/human-development-index-hdi by Tuomo Nieminen.
##### The original data combines several indicators from most countries in the world and the subset has the following variables by country:
* "GNI" = Gross National Income per capita
* "LifeExp" = Life expectancy at birth
* "ExpEduYrs" = Expected years of schooling
* "MMR" = Maternal mortality ratio
* "ABR" = Adolescent birth rate
* "FemaleParl" = Percetange of female representatives in parliament
* "EduFemale" = Proportion of females with at least secondary education
* "LabourFemale" = Proportion of females in the labour force.
The structure of the *human* dataset looks like this:
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# Print structure of the data
str(human)
```
And its summary like this:
```{r echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}
# Print summary of the data
summary(human)
```
Now, visualizing the data:
```{r echo=TRUE, error=FALSE, warning=FALSE, message=FALSE}
# Access GGally
library(GGally)
# visualize the 'human' variables
ggpairs(human)
# compute the correlation matrix and visualize it with corrplot
cor(human) %>% corrplot()
```
human = read.table("data/human.csv", sep = ";", header = TRUE)
dim(human)
str(human)
summary(human)
library(GGally)
ggpairs(human)
ggpairs(human)
cor(human) %>% corrplot()
library(GGally, dplyr)
ggpairs(human)
cor(human) %>% corrplot()
library(GGally, dplyr, corrplot)
cor(human) %>% corrplot()
?corrplot
library(GGally, dplyr, corrplot)
ggpairs(human)
cor(human) %>% corrplot()
install.packages(corrplot)
library(dplyr)
cor(human) %>% corrplot()
# Access GGally
library(GGally)
# visualize the 'human' variables
ggpairs(human)
# compute the correlation matrix and visualize it with corrplot
cor(human) %>% corrplot()
library(GGally)
library(dplyr)
library(corrplot)
cor(human) %>% corrplot()
cor(human) %>% corrplot(,type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
cor(human) %>% corrplot(,type = "lower", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
cor(human) %>% corrplot(,cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
cor(human) %>% corrplot()
p1 <- ggplot(sestuet, aes(x = Tukityypin nimi, y = Tukihakemuksen päätöseur, col = Elokuvan lajityyppi))
p1 <- ggplot(sestuet, aes(x = 'Tukityypin nimi', y = 'Tukihakemuksen päätöseur', col = 'Elokuvan lajityyppi'))
library(dplyr)
library(ggplot2)
library(ggplot2)
sestuet <- read.table("data/SES_Tukipaeaetoekset_2008-2015.csv", sep = "\t", header = TRUE)
setwd("I:/Google Drive/Helsingin yliopisto/Intro to Open Data Science/IODS-final")
sestuet <- read.table("data/SES_Tukipaeaetoekset_2008-2015.csv", sep = "\t", header = TRUE)
sestuet <- read.table("data/SES_Tukipaeaetoekset_2008-2015.csv", sep = ";", header = TRUE)
sestuet <- read.table("data/SES_Tukipaeaetoekset_2008-2015.csv", sep = ";", header = TRUE)
library(dplyr)
library(ggplot2)
elokuvat <- read.table("data/Ensi-illat_ja_katsojat_2004-2014.csv", sep = ";", header = TRUE)
elokuvat <- read.csv2("data/Ensi-illat_ja_katsojat_2004-2014.csv", header = TRUE)
stre(elokuvat)
str(elokuvat)
sestuet <- read.csv2("data/SES_Tukipaeaetoekset_2008-2015.csv", header = TRUE)
teatterit <- read.csv2("Elokuvateatterit_2015.csv", header = TRUE)
teatterit <- read.csv2("data/Elokuvateatterit_2015.csv", header = TRUE)
